{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"colab":{"name":"resnet_attention.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xk_JWOlNmNnp","colab_type":"code","colab":{}},"source":["from mxnet import gluon, nd\n","from mxnet.gluon import nn\n","import mxnet as mx\n","\n","class Residual(nn.Block):\n","  '''\n","  simple residual module\n","  '''\n","  def __init__(self, num_channels, change_shape=False, **kwargs):\n","    super(Residual, self).__init__(**kwargs)\n","    self.change_shape = change_shape\n","    strides = 1 if not change_shape else 2\n","    \n","    # conv use 3*3 filter, use strides change shape if necessery\n","    self.conv1 = nn.Conv2D(num_channels, kernel_size=3, strides=strides, padding=1)\n","    self.bn1 = nn.BatchNorm()\n","    \n","    # conv use 3*3 filter, only get more features\n","    self.conv2 = nn.Conv2D(num_channels, kernel_size=3, padding=1)\n","    self.bn2 = nn.BatchNorm()\n","    \n","    # in order to plus input and output, change input shape if output shape has changed \n","    if change_shape:\n","      self.conv3 = nn.Conv2D(num_channels, kernel_size=1, strides=strides)\n","    # SAM1\n","    self.sam1 = SAM()\n","    # SAM2\n","    self.sam2 = SAM()\n","    # CAM\n","    self.cam = CAM(num_channels, 4)\n","      \n","  def forward(self, X):\n","    Y_1 = nd.relu(self.bn1(self.conv1(X)))\n","    Y_2 = self.bn2(self.conv2(Y_1))\n","    if self.change_shape:\n","      X = self.conv3(X)\n","    sam_conv1 = self.sam1(Y_1)\n","    sam_conv2 = self.sam2(Y_2)\n","    attention_weight = self.cam((sam_conv1 + sam_conv2))\n","    X = attention_weight * X\n","    Y = nd.relu(Y_2 + X)\n","    return Y\n","\n","\n","class CAM(nn.Block):\n","  def __init__(self, num_channels, ratio, **kwargs):\n","    super(CAM, self).__init__(**kwargs)\n","    self.avg_pool = nn.GlobalAvgPool2D()\n","    self.max_pool = nn.GlobalMaxPool2D()\n","    self.conv1 = nn.Conv2D(num_channels // ratio, 1)\n","    self.conv2 = nn.Conv2D(num_channels, 1)\n","\n","  def forward(self, X):\n","    X_avg = self.conv2(\n","        nd.relu(self.conv1(self.avg_pool(X))))\n","    X_max = self.conv2(\n","        nd.relu(self.conv1(self.max_pool(X))))\n","    Y = nd.sigmoid(X_avg + X_max)\n","    return Y\n","\n","\n","class SAM(nn.Block):\n","  def __init__(self, kernel_size=7, **kwargs):\n","    super(SAM, self).__init__(**kwargs)\n","    self.kernel_size = kernel_size\n","    assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n","    self.padding = 3 if self.kernel_size == 7 else 1\n","    self.avg_pool = nn.AvgPool2D(pool_size=3, strides=2, padding=1)\n","    self.max_pool = nn.MaxPool2D(pool_size=3, strides=2, padding=1)\n","    self.conv = nn.Conv2D(1, kernel_size=self.kernel_size, strides=2, padding=self.padding)\n","\n","  def forward(self, X):\n","    X_avg = self.avg_pool(X)\n","    X_max = self.max_pool(X)\n","    Y = nd.concat(X_avg, X_max, dim=1)\n","    Y = nd.sigmoid(self.conv(Y))\n","    return Y\n","  \n","    \n","def resnet_block(num_channels, num_residuals, first_block=False):\n","  '''\n","  define resnet block\n","  '''\n","  blk = nn.Sequential()\n","  for i in range(num_residuals):\n","    if i == 0 and not first_block:\n","      # if first conv in block, need change shape\n","      blk.add(Residual(num_channels, change_shape=True))\n","    else:\n","      blk.add(Residual(num_channels))\n","  return blk\n","\n","\n","\n","\n","def Resnet_18():\n","  '''\n","  define resnet 18\n","  '''\n","  print('loading model resnet_18_attention')\n","  net = nn.Sequential()\n","  net.add(nn.Conv2D(64, kernel_size=7, strides=2, padding=3),\n","          nn.BatchNorm(), nn.Activation('relu'),\n","          nn.MaxPool2D(pool_size=3, strides=2, padding=1))\n","  \n","  net.add(resnet_block(64, 2, first_block=True),\n","          resnet_block(128, 2),\n","          resnet_block(256, 2),\n","          resnet_block(512, 2))\n","  \n","  net.add(nn.GlobalAvgPool2D(), nn.Dense(10))\n","  # net.add(nn.Conv2D(num_classes, kernel_size=1),\n","  #       nn.Conv2DTranspose(num_classes, kernel_size=64, padding=16,\n","  #                          strides=32))\n","  \n","  return net\n","\n","\n","def Resnet_34():\n","  '''\n","  define resnet 34\n","  '''\n","  print('loading model resnet_34_attention')\n","  net = nn.Sequential()\n","  net.add(nn.Conv2D(64, kernel_size=7, strides=2, padding=3),\n","          nn.BatchNorm(), nn.Activation('relu'),\n","          nn.MaxPool2D(pool_size=3, strides=2, padding=1))\n","  \n","  net.add(resnet_block(64, 3, first_block=True),\n","          resnet_block(128, 4),\n","          resnet_block(256, 6),\n","          resnet_block(512, 3))\n","  \n","  net.add(nn.GlobalAvgPool2D(), nn.Dense(10))\n","  \n","  return net"],"execution_count":0,"outputs":[]}]}
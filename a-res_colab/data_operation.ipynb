{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"colab":{"name":"data_operation.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"BbPl9qOL9IED","colab_type":"code","colab":{}},"source":["import os, utils\n","import mxnet as mx\n","from mxnet import gluon, image, nd\n","from mxnet.gluon import data\n","import cv2\n","%matplotlib inline\n","\n","VERBOSE = True\n","TRAIN_FILE = True\n","\n","\n","def get_file_name(data_dir, verbose=VERBOSE):\n","    train_dir = os.path.join(data_dir, 'SBUTrain4KRecoveredSmall', 'ShadowImages')\n","    test_dir = os.path.join(data_dir, 'SBU-Test', 'ShadowImages')\n","    \n","    # get all file name without ext\n","    train_file_name = list(map(lambda x:os.path.splitext(x)[0], os.listdir(train_dir)))\n","    test_file_name = list(map(lambda x:os.path.splitext(x)[0], os.listdir(test_dir)))\n","    \n","    if verbose:\n","        print('Get {} train image, {} test image.'.format(len(train_file_name), len(test_file_name)))\n","        \n","    return train_file_name, test_file_name\n","\n","\n","def read_file(data_dir, train_file, verbose=VERBOSE):\n","    if train_file:\n","        file_name, _ = get_file_name(data_dir)\n","        data_dir = os.path.join(data_dir, 'SBUTrain4KRecoveredSmall')\n","    else:\n","        _, file_name = get_file_name(data_dir)\n","        data_dir = os.path.join(data_dir, 'SBU-Test')\n","        \n","    features, labels = [None] * len(file_name), [None] * len(file_name)\n","    \n","    for i, fname in enumerate(file_name):\n","        features[i] = image.imread('{}/ShadowImages/{}.jpg'.format(data_dir, fname))\n","        labels[i] = image.imread('{}/ShadowMasks/{}.png'.format(data_dir, fname))\n","        if verbose and i%500 == 0:\n","            print('{} images loaded...'.format(i))\n","    \n","    if verbose and train_file:\n","        print('Loaded all {} features and labels on train dataset.'.format(len(features)))\n","    elif verbose and not train_file:\n","        print('Loaded all {} features and labels on test dataset.'.format(len(features)))\n","        \n","    return features, labels\n","\n","    \n","def label_transform(img):\n","    img = cv2.cvtColor(img.asnumpy(), cv2.COLOR_RGB2GRAY)\n","    img = img / 255.\n","    return nd.array(img)\n","    \n","\n","# random crop\n","def random_crop(feature, label, width, height):\n","    # image.random_crop(data, height, width) different with the array's shape (width height)\n","    feature, rect = image.random_crop(feature, (height, width))\n","    label = image.fixed_crop(label, *rect)\n","    return feature, label\n","\n","\n","class ShadowDataset(data.Dataset):\n","    def __init__(self, train_file, crop_size, data_dir, verbose=True):\n","        self.rgb_mean = nd.array([0.485, 0.456, 0.406])\n","        self.rgb_std = nd.array([0.229, 0.224, 0.225])\n","        self.crop_size = crop_size\n","        features, labels = read_file(data_dir, train_file=train_file)\n","        self.features = [self.normalize_image(feature)\n","                         for feature in self.filter(features)]\n","        self.labels = self.filter(labels)\n","        if verbose:\n","          print('Remain {} images can be cropped and normalized.'.format(len(self.features)))\n","            \n","    # drop img with error size which cannot be cropped\n","    def filter(self, imgs):\n","        new_imgs = []\n","        for img in imgs:\n","          if img.shape[0] >= self.crop_size[0] and img.shape[1] >= self.crop_size[1]:\n","            new_imgs.append(img)\n","        \n","        return new_imgs\n","    \n","    def normalize_image(self, img):\n","        return (img.astype('float32') / 255 - self.rgb_mean) / self.rgb_std\n","    \n","    def __getitem__(self, index):\n","        feature, label = random_crop(self.features[index], self.labels[index], *self.crop_size)\n","        return (feature.transpose((2, 0, 1)), label_transform(label))\n","\n","    def __len__(self):\n","      return len(self.features)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ep-f0ucp9IEL","colab_type":"code","colab":{}},"source":["def test_read():\n","    features, labels = read_file(train_file=True)\n","    imgs = features[0:5] + labels[0:5]\n","    utils.show_images(imgs, 2, 5)\n","    \n","# test_read()\n","\n","def test_crop():\n","    features, labels = read_file(train_file=True)\n","    imgs = []\n","    for _ in range(5):\n","        imgs += random_crop(features[0], labels[0], 300, 200)\n","    utils.show_images(imgs[::2] + imgs[1::2], 2, 5);\n","\n","# test_crop()"],"execution_count":0,"outputs":[]}]}